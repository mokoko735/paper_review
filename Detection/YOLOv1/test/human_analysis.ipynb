{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append('../YOLOv1')\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from dataset import VOCDataset\n",
    "from model import YOLOv1\n",
    "from loss import YoloLoss1, YoloLoss2\n",
    "from trainer import Trainer\n",
    "from config import config\n",
    "\n",
    "config = config()\n",
    "\n",
    "config.batch_size = 16\n",
    "config.lr = 2e-5\n",
    "config.device='cuda'\n",
    "\n",
    "config.print_interval = 50\n",
    "config.model_dir = '../checkpoints/experiment2'\n",
    "config.load_model_path = os.path.join(config.model_dir, 'YOLOv1_180epoch.pt')\n",
    "\n",
    "config.dataset_dir = r'D:\\AI\\Dataset\\VocDetection2'\n",
    "config.img_dir = os.path.join(config.dataset_dir, 'images')\n",
    "config.label_dir = os.path.join(config.dataset_dir, 'labels')\n",
    "config.train_csv = os.path.join(config.dataset_dir, 'train.csv')\n",
    "config.valid_csv = os.path.join(config.dataset_dir, 'valid.csv')\n",
    "\n",
    "config.save_csv_path = os.path.join(config.model_dir, 'YOLOv1_result.csv')\n",
    "\n",
    "train_dataset = VOCDataset(\n",
    "    config.train_csv,\n",
    "    config.img_dir,\n",
    "    config.label_dir,\n",
    "    config.img_size,\n",
    "    config.S, config.B, config.C,\n",
    "    config.test_transform,\n",
    "    return_img_path=True,\n",
    ")\n",
    "valid_dataset = VOCDataset(\n",
    "    config.valid_csv,\n",
    "    config.img_dir,\n",
    "    config.label_dir,\n",
    "    config.img_size,\n",
    "    config.S, config.B, config.C,\n",
    "    config.test_transform,\n",
    "    return_img_path=True,\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    dataset=valid_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "model = YOLOv1(config.S, config.B, config.C).to(config.device)\n",
    "optimizer = optim.Adam(model.parameters(), config.lr)\n",
    "crit = YoloLoss2(config.S, config.B, config.C)\n",
    "trainer = Trainer(model, optimizer, crit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "now loading.....\n",
      "resume epoch: 181 lowest loss: 37.78397787184942\n",
      "\n",
      "[1/759] test loss: 17.3782\n",
      "[51/759] test loss: 13.6361\n",
      "[101/759] test loss: 6.6943\n",
      "[151/759] test loss: 7.0980\n",
      "[201/759] test loss: 17.3682\n",
      "[251/759] test loss: 11.6920\n",
      "[301/759] test loss: 17.9308\n",
      "[351/759] test loss: 12.5553\n",
      "[401/759] test loss: 8.7950\n",
      "[451/759] test loss: 13.4154\n",
      "[501/759] test loss: 11.0005\n",
      "[551/759] test loss: 10.6583\n",
      "[601/759] test loss: 11.2985\n",
      "[651/759] test loss: 14.5172\n",
      "[701/759] test loss: 19.6226\n",
      "[751/759] test loss: 9.2087\n"
     ]
    }
   ],
   "source": [
    "losses, pred_bboxes, true_bboxes, img_paths = trainer.test(train_loader, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append('../YOLOv1')\n",
    "\n",
    "from utils import analyze_error\n",
    "\n",
    "csv_path = './experiment2_error_analysis.csv'\n",
    "analyze_error(pred_bboxes, true_bboxes, img_paths, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>train_idx</th>\n",
       "      <th>gt_class</th>\n",
       "      <th>gt_conf</th>\n",
       "      <th>gt_x</th>\n",
       "      <th>gt_y</th>\n",
       "      <th>gt_w</th>\n",
       "      <th>gt_h</th>\n",
       "      <th>dt_class</th>\n",
       "      <th>dt_conf</th>\n",
       "      <th>dt_x</th>\n",
       "      <th>dt_y</th>\n",
       "      <th>dt_w</th>\n",
       "      <th>dt_h</th>\n",
       "      <th>iou</th>\n",
       "      <th>error_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D:\\AI\\Dataset\\VocDetection2\\images\\2008_006148...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.321000</td>\n",
       "      <td>0.50600</td>\n",
       "      <td>0.638000</td>\n",
       "      <td>0.738000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.967628</td>\n",
       "      <td>0.308723</td>\n",
       "      <td>0.510902</td>\n",
       "      <td>0.634000</td>\n",
       "      <td>0.730596</td>\n",
       "      <td>0.930621</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D:\\AI\\Dataset\\VocDetection2\\images\\2010_000337...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.602000</td>\n",
       "      <td>0.73500</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602000</td>\n",
       "      <td>0.735000</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>not detected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D:\\AI\\Dataset\\VocDetection2\\images\\2007_005691...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.499883</td>\n",
       "      <td>0.50100</td>\n",
       "      <td>0.429738</td>\n",
       "      <td>0.998000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.059777</td>\n",
       "      <td>0.496484</td>\n",
       "      <td>0.507719</td>\n",
       "      <td>0.426793</td>\n",
       "      <td>0.993650</td>\n",
       "      <td>0.937537</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D:\\AI\\Dataset\\VocDetection2\\images\\2010_004059...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.499000</td>\n",
       "      <td>0.57586</td>\n",
       "      <td>0.742000</td>\n",
       "      <td>0.393878</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.906602</td>\n",
       "      <td>0.499543</td>\n",
       "      <td>0.562860</td>\n",
       "      <td>0.784091</td>\n",
       "      <td>0.415121</td>\n",
       "      <td>0.905706</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D:\\AI\\Dataset\\VocDetection2\\images\\2012_000918...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.322000</td>\n",
       "      <td>0.35200</td>\n",
       "      <td>0.404000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.993183</td>\n",
       "      <td>0.317514</td>\n",
       "      <td>0.354409</td>\n",
       "      <td>0.443219</td>\n",
       "      <td>0.435424</td>\n",
       "      <td>0.979343</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>D:\\AI\\Dataset\\VocDetection2\\images\\2012_000918...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.322000</td>\n",
       "      <td>0.35200</td>\n",
       "      <td>0.404000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.993183</td>\n",
       "      <td>0.317514</td>\n",
       "      <td>0.354409</td>\n",
       "      <td>0.443219</td>\n",
       "      <td>0.435424</td>\n",
       "      <td>0.979343</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>D:\\AI\\Dataset\\VocDetection2\\images\\2012_000918...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.636000</td>\n",
       "      <td>0.54500</td>\n",
       "      <td>0.352000</td>\n",
       "      <td>0.636000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.761551</td>\n",
       "      <td>0.636347</td>\n",
       "      <td>0.532185</td>\n",
       "      <td>0.353135</td>\n",
       "      <td>0.623676</td>\n",
       "      <td>0.761233</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>D:\\AI\\Dataset\\VocDetection2\\images\\2012_000918...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.636000</td>\n",
       "      <td>0.54500</td>\n",
       "      <td>0.352000</td>\n",
       "      <td>0.636000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.761551</td>\n",
       "      <td>0.636347</td>\n",
       "      <td>0.532185</td>\n",
       "      <td>0.353135</td>\n",
       "      <td>0.623676</td>\n",
       "      <td>0.761233</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>D:\\AI\\Dataset\\VocDetection2\\images\\2010_001120...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.285000</td>\n",
       "      <td>0.70500</td>\n",
       "      <td>0.316000</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.861552</td>\n",
       "      <td>0.514960</td>\n",
       "      <td>0.634680</td>\n",
       "      <td>0.260682</td>\n",
       "      <td>0.515887</td>\n",
       "      <td>0.508239</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>D:\\AI\\Dataset\\VocDetection2\\images\\2010_001120...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.285000</td>\n",
       "      <td>0.70500</td>\n",
       "      <td>0.316000</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.861552</td>\n",
       "      <td>0.514960</td>\n",
       "      <td>0.634680</td>\n",
       "      <td>0.260682</td>\n",
       "      <td>0.515887</td>\n",
       "      <td>0.508239</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            img_path  train_idx  gt_class  \\\n",
       "0  D:\\AI\\Dataset\\VocDetection2\\images\\2008_006148...        0.0      14.0   \n",
       "1  D:\\AI\\Dataset\\VocDetection2\\images\\2010_000337...        1.0      10.0   \n",
       "2  D:\\AI\\Dataset\\VocDetection2\\images\\2007_005691...        2.0      14.0   \n",
       "3  D:\\AI\\Dataset\\VocDetection2\\images\\2010_004059...        3.0       6.0   \n",
       "4  D:\\AI\\Dataset\\VocDetection2\\images\\2012_000918...        4.0      14.0   \n",
       "5  D:\\AI\\Dataset\\VocDetection2\\images\\2012_000918...        4.0      14.0   \n",
       "6  D:\\AI\\Dataset\\VocDetection2\\images\\2012_000918...        4.0      14.0   \n",
       "7  D:\\AI\\Dataset\\VocDetection2\\images\\2012_000918...        4.0      14.0   \n",
       "8  D:\\AI\\Dataset\\VocDetection2\\images\\2010_001120...        5.0      14.0   \n",
       "9  D:\\AI\\Dataset\\VocDetection2\\images\\2010_001120...        5.0      14.0   \n",
       "\n",
       "   gt_conf      gt_x     gt_y      gt_w      gt_h  dt_class   dt_conf  \\\n",
       "0      1.0  0.321000  0.50600  0.638000  0.738000      14.0  0.967628   \n",
       "1      1.0  0.602000  0.73500  0.304000  0.280000      10.0  1.000000   \n",
       "2      1.0  0.499883  0.50100  0.429738  0.998000      14.0  1.059777   \n",
       "3      1.0  0.499000  0.57586  0.742000  0.393878       6.0  0.906602   \n",
       "4      1.0  0.322000  0.35200  0.404000  0.450000      14.0  0.993183   \n",
       "5      1.0  0.322000  0.35200  0.404000  0.450000      14.0  0.993183   \n",
       "6      1.0  0.636000  0.54500  0.352000  0.636000      14.0  0.761551   \n",
       "7      1.0  0.636000  0.54500  0.352000  0.636000      14.0  0.761551   \n",
       "8      1.0  0.285000  0.70500  0.316000  0.590000      14.0  0.861552   \n",
       "9      1.0  0.285000  0.70500  0.316000  0.590000      14.0  0.861552   \n",
       "\n",
       "       dt_x      dt_y      dt_w      dt_h       iou    error_type  \n",
       "0  0.308723  0.510902  0.634000  0.730596  0.930621       correct  \n",
       "1  0.602000  0.735000  0.304000  0.280000  0.000000  not detected  \n",
       "2  0.496484  0.507719  0.426793  0.993650  0.937537       correct  \n",
       "3  0.499543  0.562860  0.784091  0.415121  0.905706       correct  \n",
       "4  0.317514  0.354409  0.443219  0.435424  0.979343       correct  \n",
       "5  0.317514  0.354409  0.443219  0.435424  0.979343       correct  \n",
       "6  0.636347  0.532185  0.353135  0.623676  0.761233       correct  \n",
       "7  0.636347  0.532185  0.353135  0.623676  0.761233       correct  \n",
       "8  0.514960  0.634680  0.260682  0.515887  0.508239       correct  \n",
       "9  0.514960  0.634680  0.260682  0.515887  0.508239       correct  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def save_img(img, bboxes, class_names, colors, mean, std, analysis=True, save_path=None):\n",
    "    '''\n",
    "    parameters:\n",
    "        img (tensor): [C, H, W]\n",
    "        bboxes (tensor): [class_prediction, prob_score, x, y, w, h]\n",
    "        class_names (list): 데이터셋의 클래스명\n",
    "        colors (list): 색상 리스트\n",
    "    '''\n",
    "\n",
    "    img_size = [img.shape[1], img.shape[2]] # height, width\n",
    "\n",
    "    img = inverse_normalize(img, mean, std)\n",
    "    img = np.array(img, dtype=np.uint8)\n",
    "    img = np.transpose(img, (1, 2, 0)) # [C, H, W] -> [H, W, C]\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    for bbox in bboxes:\n",
    "        class_label = int(bbox[0])\n",
    "        prob = bbox[1]\n",
    "        coord = bbox[2:6]\n",
    "\n",
    "        x1, y1, x2, y2 = convert_box_format(img_size, coord)\n",
    "        color = colors[class_label]\n",
    "\n",
    "        if analysis:\n",
    "            error_type = bbox[6]\n",
    "            text = class_names[class_label] + f\" | {prob:0.2f} | {error_type}\"\n",
    "            text_len = 12*len(text)\n",
    "        else:\n",
    "            text = class_names[class_label] + f\" | {prob:0.2f}\"\n",
    "            text_len = 9*len(text)\n",
    "            \n",
    "        if y1 <= 16:\n",
    "            rect_coord = [[x1, y1], [x1+text_len, y1+13]]\n",
    "            text_coord = [x1, y1+11]\n",
    "        else:\n",
    "            rect_coord = [[x1, y1-16], [x1+text_len, y1]]\n",
    "            text_coord = [x1, y1-3]\n",
    "\n",
    "        cv2.rectangle(img, (x1,y1), (x2,y2), color, thickness=2)\n",
    "        cv2.rectangle(img, rect_coord[0], rect_coord[1], color, thickness=-1)\n",
    "        cv2.putText(\n",
    "            img, text=text, org=text_coord, fontFace=cv2.FONT_HERSHEY_SIMPLEX, \n",
    "            fontScale=0.5, thickness=1, lineType=cv2.LINE_AA, color=(255, 255, 255)\n",
    "        )\n",
    "        cv2.imwrite(save_path, img)\n",
    "\n",
    "def inverse_normalize(img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\n",
    "    '''\n",
    "    parameters:\n",
    "        img (tensor): [C, H, W]\n",
    "    '''\n",
    "    \n",
    "    img[0] = ((img[0]) * std[0]) + mean[0]\n",
    "    img[1] = ((img[1]) * std[1]) + mean[1]\n",
    "    img[2] = ((img[2]) * std[2]) + mean[2]\n",
    "    img = 255 * img\n",
    "\n",
    "    return img\n",
    "\n",
    "def set_color(num_classes):\n",
    "    import random\n",
    "\n",
    "    colors = []\n",
    "    for i in range(num_classes):\n",
    "        b = random.randint(0, 100) # 100 이상의 밝은 색은 눈부심\n",
    "        g = random.randint(0, 100)\n",
    "        r = random.randint(0, 100)\n",
    "        colors.append([b, g, r])\n",
    "\n",
    "    return colors\n",
    "\n",
    "def convert_box_format(img_size, coordinate):\n",
    "    # normalized [x_center, y_center, width, height] -> [x_min, y_min, x_max, y_max]\n",
    "    img_height, img_width = img_size\n",
    "\n",
    "    xmin = int(img_width * (2 * coordinate[0] - coordinate[2]) / 2)\n",
    "    ymin = int(img_height * (2 * coordinate[1] - coordinate[3]) / 2)\n",
    "    xmax = int(img_width * (2 * coordinate[0] + coordinate[2]) / 2)\n",
    "    ymax = int(img_height * (2 * coordinate[1] + coordinate[3]) / 2)\n",
    "    \n",
    "    coord = [xmin, ymin, xmax, ymax]\n",
    "\n",
    "    return coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from utils import draw, set_color\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.Normalize(mean=config.mean, std=config.std, max_pixel_value=255),\n",
    "    A.LongestMaxSize(max_size=config.img_size),\n",
    "    A.PadIfNeeded(\n",
    "        min_height=config.img_size,\n",
    "        min_width=config.img_size,\n",
    "        border_mode=cv2.BORDER_CONSTANT,\n",
    "    ),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "class_names = config.voc_classes\n",
    "colors = set_color(len(class_names))\n",
    "\n",
    "for train_idx in tqdm(range(0, int(df['train_idx'].max())+1)):\n",
    "    temp_df = df[df['train_idx'] == train_idx]\n",
    "\n",
    "    img_path = temp_df['img_path'].values[0]\n",
    "    image = np.array(Image.open(img_path).convert('RGB'))\n",
    "\n",
    "    augmentations = test_transform(image=image)\n",
    "    image = augmentations['image']\n",
    "\n",
    "    gt_df = temp_df.iloc[:, 2:8]\n",
    "    gt_df.columns = ['class', 'confidence', 'x', 'y', 'w', 'h']\n",
    "    gt_df['error_type'] = 'target'\n",
    "\n",
    "    dt_df = temp_df.iloc[:, 8:14]\n",
    "    dt_df.columns = ['class', 'confidence', 'x', 'y', 'w', 'h']\n",
    "    dt_df['error_type'] = temp_df.iloc[:, 15]\n",
    "\n",
    "    bboxes= pd.concat([gt_df, dt_df]).values\n",
    "\n",
    "    save_dir = './images'\n",
    "    file_name = img_path.split('\\\\')[-1]\n",
    "    save_path = os.path.join(save_dir, file_name)\n",
    "\n",
    "    draw(image, bboxes, class_names, colors, config.mean, config.std, analysis=True)\n",
    "    # save_img(image, bboxes, class_names, colors, config.mean, config.std, analysis=True, save_path=save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
